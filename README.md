ğŸ§  Medical RAG Agent â€” Context-Aware Healthcare Question Answering System
ğŸš€ Overview

The Medical RAG Agent is a Retrieval-Augmented Generation (RAG) system built to deliver accurate, explainable, and source-grounded answers to medical questions.
It combines document retrieval, reranking, and large-language-model reasoning using LlamaIndex, LangChain, Together API, and ChromaDB â€” ensuring both factual precision and clinical reliability.

ğŸ§© Key Features

âœ… Parse and embed medical PDFs with LlamaParse + BGE embeddings
âœ… Store document vectors in ChromaDB (persistent local DB)
âœ… Retrieve and rerank relevant context using Llama-Rank-v1
âœ… Generate fact-grounded answers using Meta-Llama-3.1-70B-Instruct-Turbo
âœ… Deploy through FastAPI, with endpoints for ingestion, retrieval, and generation
âœ… Scalable and ready for Docker + AWS ECS/RDS + CloudWatch monitoring

âš™ï¸ System Architecture

Backend/
â”œâ”€â”€ Ingestion/
â”‚   â”œâ”€â”€ document_parser.py     # LlamaParse PDF parser
â”‚   â”œâ”€â”€ embedder.py            # Embeddings generator (BGE)
â”‚   â”œâ”€â”€ vector_store.py        # Vector storage using ChromaDB
â”‚
â”œâ”€â”€ retrieval/
â”‚   â”œâ”€â”€ retriever.py           # Context search + reranking
â”‚
â”œâ”€â”€ generator/
â”‚   â”œâ”€â”€ generator.py           # LLM-based context-grounded answer generator
â”‚
â”œâ”€â”€ main.py                    # FastAPI entry point (API endpoints)
â”‚
â”œâ”€â”€ data/                      # Medical PDFs and extracted data
â”‚   â”œâ”€â”€ Full.pdf
â”‚   â”œâ”€â”€ uploads/
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


ğŸ§  RAG Flow

Ingest Documents â€” Parse PDFs using LlamaParse
Chunk + Embed â€” Generate vector embeddings (BGE model)
Store â€” Save embeddings to ChromaDB
Retrieve â€” Fetch top-k relevant context chunks
Rerank â€” Optimize order with Llama-Rank-v1
Generate â€” Produce medically-accurate answer with Together API (Llama-3.1-70B)


| Layer          | Technology                                |
| :------------- | :---------------------------------------- |
| **LLM**        | Meta-Llama-3.1-70B-Instruct-Turbo         |
| **Embeddings** | BAAI/bge-large-en-v1.5                    |
| **Reranker**   | Salesforce/Llama-Rank-v1                  |
| **Vector DB**  | ChromaDB                                  |
| **Backend**    | FastAPI                                   |
| **Deployment** | Docker, AWS ECS, RDS/pgvector, CloudWatch |
| **Parser**     | LlamaParse                                |
| **Language**   | Python 3.11                               |
